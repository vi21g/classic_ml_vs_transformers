# Классификация текста с помощью трансформеров: сравнительный анализ с традиционными методами.

[Ссылка на Google Colab](https://colab.research.google.com/drive/11KePQWrrzquSrzvSeDm60C3YqN2SDP__?usp=sharing)

## Аннотация
В данной работе проводится сравнительный анализ эффективности современных трансформерных моделей (на примере дообученной BERT-подобной архитектуры) и классических методов машинного обучения, таких как Logistic Regression, XGBoost и SVM, в задаче классификации текстов. Основная цель работы — определить, в каких сценариях трансформеры демонстрируют значительное преимущество перед традиционными подходами, а когда более простые методы остаются конкурентноспособными. Результаты могут быть полезны для выбора оптимального инструментария в прикладных NLP-задачах с учётом ограничений на вычислительные ресурсы.

## Почему ссылка на колаб а не репозиторий?
В данной работе также прилагается ссылка на **Google Colab** с реализацией экспериментов. Это сделано по той причине, что GitHub не отображает содержимое файла `.ipynb` (Jupyter Notebook) при наличии проблем с версиями. Однако сам файл **`ipynb`** будет сохранён в репозитории, и его можно скачать для локального просмотра в любой поддерживающей среде разработки (IDE), такой как **Jupyter Notebook, JupyterLab или VS Code с расширением для Python**.  

Таким образом, читатели смогут:  
- **Интерактивно изучить код и результаты** в Colab (без необходимости скачивания).  
- **Загрузить ноутбук** и запустить его локально при наличии вычислительных ресурсов.  
- **Просмотреть воспроизводимые эксперименты**, включая предобработку данных, обучение моделей и сравнительный анализ.  
